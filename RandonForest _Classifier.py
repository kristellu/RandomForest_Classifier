# -*- coding: utf-8 -*-
"""PUNTO3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lbNbkbG4OLxQMqrWQhc4_VeQJAhT2UnN

*Presentado por: Cristian Yepes - Sharon Figueroa - Kristell Urueta*

## **Sistema de clasificación basado en Random Forest**

Para el diseño e implementación de un sistema capaz de detectar y clasificar los digitos escritos a mano y provistos por el dataset de Scikit Learn (sklearn.datasets.load_digits), se siguieron los siguientes pasos:

1.   Carga del dataset "load_digits".
2.   División de los datos en 70% elementos de entrenamiento, 30% de validación.
3.   Construcción del modelo de clasificación Random Forest con 5 variaciones del número de arboles y características.
3.   Validación del modelo y de posibles variables de respuesta/objetivo, mediante el análisis de curvas ROC para cada clase (digitos entre 0-9).
4.   Gráfica de importancia de características para medir la variabilidad del modelo cuando se afectan las variables de entrada.
5.   Comparación de resultados obtenidos.

Muestra del dataset load_digits:
"""

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn.datasets import load_digits
from sklearn.datasets import make_moons, make_circles, make_classification
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis

# just plot the dataset first
digits = load_digits()
digits.keys()

# set up the figure
fig = plt.figure(figsize=(5, 5))  # figure size in inches
fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)

# plot the digits: each image is 8x8 pixels
for i in range(64):
    ax = fig.add_subplot(8, 8, i + 1, xticks=[], yticks=[])
    ax.imshow(digits.images[i], cmap=plt.cm.binary, interpolation='nearest')
    
    # label the image with the target value
    ax.text(0, 7, str(digits.target[i]))
plt.figure()

"""Carga y reporte de clasificación para el dataset:"""

from sklearn.model_selection import train_test_split
from sklearn import metrics

x, y = load_digits(return_X_y=True)
x_train, x_test, y_train, y_test = train_test_split(x,y,train_size=.7)
model = RandomForestClassifier(n_estimators=1000)
model.fit(x_train,  y_train)
y_pred = model.predict(x_test)
print(metrics.classification_report(y_pred, y_test))
clf=[]

"""Matriz de confusión:"""

# ---------Descomentar en caso de querer verla
# #CONFUSION MATRIX
# index = y_test == 0
# y_prob = clf.predict_proba(x_test[index])[:,0]
# fpr_rt_tb, tpr_rt_tb, th = roc_curve(y_test[index], y_prob)
# roc_auc = auc(fpr_rt_tb, tpr_rt_tb)
# from sklearn.metrics import confusion_matrix

# clf.fit(x_train, y_train)
# y_predict = clf.predict(x_test[index])
# CM = confusion_matrix(y_test[index], y_predict)

# disp = metrics.plot_confusion_matrix(clf, x_test[index], y_test[index])
# disp.figure_.suptitle("Confusion Matrix")

"""Función para dibujar curva ROC de cada clase y aplicación del clasificador:"""

# CURVA ROC
def plot_subfigure(clf, subplot, title, clase):
  yroc=[]
  for i in range(len(y_test)):
    if y_test[i]==clase:
      yroc.append(1)
    else:
      yroc.append(0)
  y_prob = clf.predict_proba(x_test)[:,clase]
  fp, tp, th = roc_curve(yroc, y_prob)
  roc_auc = auc(fp, tp)

  #Filas:2
  #Columnas: 5
  plt.subplot(2, 5, subplot)
  lw = 2
  plt.plot(fp, tp, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)
  plt.plot([0, 1], [0, 1], color='blue', linestyle='--')
  plt.xlim([-0.02, 1.5])
  plt.ylim([0.0, 1.05])
  plt.title('RANDOM FOREST - CLASS ' + str(clase))
  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
  plt.legend(loc="lower right")

"""Definición del clasificador con variación de número de arboles y características:"""

def classifier(narboles, ncar):
  plt.figure(figsize=(27, 9))
  clf = RandomForestClassifier(
          n_estimators =narboles,  #Número de árboles.
          max_features=ncar  #Número de características
          )
  clf.fit(x_train, y_train)
  print("")
  print("\033[4;34m"+"NÚMERO DE ARBOLES = " + str(narboles) +" | " + str(ncar*100)+"% DE CARACTERÍSTICAS") 
  print("")
  for i in range(10):
    plot_subfigure(clf, i+1, "RANDOM FOREST - CLASS ", i)
  plt.subplots_adjust(.04, .04, .97, .94, .2, .3)
  plt.show()
  features_importance(clf)

"""Función para determinar importancia de las características para cada clasificador:"""

def features_importance(classifier):
  importances = classifier.feature_importances_
  std = np.std([tree.feature_importances_ for tree in classifier.estimators_],
              axis=0)
  indices = np.argsort(importances)[::-1]

  # Plot the feature importances of the forest
  plt.figure(figsize=(15,4))
  plt.title("Feature importances")
  plt.bar(range(x.shape[1]), importances[indices],
        color="b", yerr=std[indices], align="center")

  plt.xticks(range(x.shape[1]), indices,rotation=90, fontsize = 8)
  plt.xlim([-1, x.shape[1]])
  plt.show()

"""**INICIO DE PRUEBAS CON VARIACIÓN DE NÚMERO DE ÁRBOLES Y CARACTERÍSTICAS**



---
*   0 < Numero de características entre <= 1
*   Número de arboles <= 1000
"""

classifier(10, 0.2)

classifier(200,0.33)

classifier(500, 0.5)

classifier(1000, 0.8)

classifier(1000, 0.99)

classifier(20,0.99)

"""**Conclusiones**:


---
Al observar las gráficas de importancias de características o feature_importances se puede notar cuáles son las que explican mejor el modelo, sin embargo, no se asegura si las mismas son correctas o no, considerando su selección aleatoria. Teniendo en cuenta esto se puede concluir que:
*   De las 64 características evaluadas del dataset, aproximadamente un 20% no brindan información relevante y un 80% de las características son informativas.

Por otro lado, en referencia al clasificador se puede decir:
*   El porcentaje en número de características es proporcial a la importancia de estas.
*   A mayor número de arboles existe mayor probabilidad de acierto en la validación de datos.
*   El clasificador Random Forest ofrece una gran efectividad para la clasificación de los datos.
*  Para las clases: 3,4, 8 y 9 en la mayoría de intentos, el modelo tiene mayor dificultad de validación, como se puede observar sus curvas ROC de cada clasificador.
"""

import pandas as pd
#pd.DataFrame(clf.predict_proba(x_test[index]))